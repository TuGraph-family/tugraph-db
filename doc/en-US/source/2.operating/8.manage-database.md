# Database Management

> This document describes common database management functions, such as log information, data export, data backup, and data warm-up

## Log information

TuGraph keeps two types of logs: server logs and audit logs. Server logs record human-readable information about the state of the server, while audit logs maintain encrypted information about each operation performed on the server.

### Server log

Server logs track server status (such as server startup/stop), and the requests that the server has provided and their corresponding responses. The details of server logs can be configured using the 'verbose' option. The log location is specified in the 'log_dir' option.

The default 'verbose' level is' 1 '. Under this level, the server only prints logs about major events, such as server startup/stop. Requests and responses are not logged at this level.

### Audit log

Audit logs record each request and response, as well as the user who sent the request and when the request received. Audit logging can only be turned on or off. The results can be queried using the TuGraph visualization tool and the REST API.

## Data export

TuGraph can use the tool 'lgraph_export' to export data from the database that has been imported successfully. The 'lgraph_export' tool can export the data of the specified TuGraph database to the specified directory in the form of 'csv' or 'json' file, and export the configuration file 'import.config'. That required for re-importing the data. Detailed description see [] configuration file (# % E9%85% AE BD E7 8 d % % % % E6%96% % 87% % E4 BB B6).

The following is an example of a command for the tool:

```bash
$ lgraph_export -d {database_dir} -e {export_destination_dir} -g {graph_to_use} -u {username} -p {password} -f  {output_format}
```

Details:

- '-d {database_dir}' specifies the directory of the database from which the data will be exported. The default value is./testdb '.
- '-e {export_destination_dir}' specifies the directory where the export file is stored. The default value is./exportdir.
- '-g {graph_to_use}' specifies the type of graph database. default is' default '.
- '-u {username}' Specifies the name of the user who performs the export operation.
- '-p {password}' Specifies the password of the user who performs the export operation.
- '-s {field_separator}' specifies the separator for the exported file. The default is comma.
- '-f {output_format}' specifies the format of the exported data. It can be 'json' or 'csv'.
- '-h' In addition to the specified parameters, you can also use this parameter to view the help of the tool.

## Data backup

TuGraph can use the 'lgraph_backup' tool to backup data.
The 'lgraph_backup' tool can backup data from a TuGraph database to another directory. It can be used as follows:

```bash
$ lgraph_backup -s {source_dir} -d {destination_dir} -c {true/false}
```

Details:

- '-s {source_dir}' specifies the directory where the database (source database) to be backed up resides.
- '-d {destination_dir}' specifies the directory where the backup file (destination database) is stored.
  If the target database is not empty, 'lgraph_backup' prompts you whether to overwrite the database.
- '-c {true/false}' indicates whether a compaction occurs during backup.
  Every compaction creates a tighter backup, but every compaction takes longer to create. This option defaults to 'true'.

## Data Warm-up

TuGraph is a disk-based database where data loaded into memory only when accessed. Therefore, for a period of time after the server just turned on, the system performance may be degraded due to frequent IO operations. At this point, we can improve this problem by data warm-up.

Data warmup can be done using the tool lgraph_warmup. An example of its use is as follows:

```bash
$ lgraph_warmup -d {directory} -g {graph_list}
```

Details:

The - '-d {db_dir}' option specifies the data directory for the TuGraph server

The - '-g {graph_list}' option specifies the names of graphs to be warmed-up, separated by commas

The warm-up process takes different times depending on the data size and the type of disk being used. Preheating a large database on a mechanical disk may take a long time. Please wait patiently.
