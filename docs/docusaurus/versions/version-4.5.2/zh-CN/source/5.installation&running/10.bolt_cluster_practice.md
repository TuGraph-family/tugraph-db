# bolt 高可用集群模式实践

> 此文档主要介绍如何通过 Bolt 协议连接并使用高可用集群。

## 创建集群

以下是创建一个包含三个节点的集群示例。

### 前期准备

在每个节点上拉取镜像并启动 Docker 容器。

1. 拉取镜像

```
docker pull tugraph/tugraph-runtime-centos7:latest
```

2. 启动docker

```
docker run --net=host -itd -v /root/tugraph/data:/var/lib/lgraph/data  -v /root/tugraph/log:/var/log/lgraph_log \
--name tugraph_ha ${REPOSITORY}:${VERSION} /bin/bash
```

### 节点配置

修改每个节点的配置文件，配置文件默认是容器内/usr/local/etc/lgraph.json。


节点1

```json
{
  "directory" : "/var/lib/lgraph/data",
  "host" : "172.20.10.52",
  "port" : 7070,
  "bolt_port": 7687,
  "bolt_raft_port":8000,
  "bolt_raft_node_id":1,
  "bolt_raft_init_peers":[
    {"bolt_raft_node_id":1,"ip":"172.20.10.52","bolt_raft_port":8000,"bolt_port":7687},
    {"bolt_raft_node_id":2,"ip":"172.20.10.53","bolt_raft_port":8000,"bolt_port":7687},
    {"bolt_raft_node_id":3,"ip":"172.20.10.54","bolt_raft_port":8000,"bolt_port":7687}
  ],
  "verbose" : 1,
  "log_dir" : "/var/log/lgraph_log",
  "disable_auth" : false,
  "ssl_auth" : false,
  "server_key" : "/usr/local/etc/lgraph/server-key.pem",
  "server_cert" : "/usr/local/etc/lgraph/server-cert.pem",
  "web" : "/usr/local/share/lgraph/browser-resource"
}
```

节点2

```json
{
  "directory" : "/var/lib/lgraph/data",
  "host" : "172.20.10.53",
  "port" : 7070,
  "bolt_port": 7687,
  "bolt_raft_port":8000,
  "bolt_raft_node_id":2,
  "bolt_raft_init_peers":[
    {"bolt_raft_node_id":1,"ip":"172.20.10.52","bolt_raft_port":8000,"bolt_port":7687},
    {"bolt_raft_node_id":2,"ip":"172.20.10.53","bolt_raft_port":8000,"bolt_port":7687},
    {"bolt_raft_node_id":3,"ip":"172.20.10.54","bolt_raft_port":8000,"bolt_port":7687}
  ],
  "verbose" : 1,
  "log_dir" : "/var/log/lgraph_log",
  "disable_auth" : false,
  "ssl_auth" : false,
  "server_key" : "/usr/local/etc/lgraph/server-key.pem",
  "server_cert" : "/usr/local/etc/lgraph/server-cert.pem",
  "web" : "/usr/local/share/lgraph/browser-resource"
}
```

节点3

```json
{
  "directory" : "/var/lib/lgraph/data",
  "host" : "172.20.10.54",
  "port" : 7070,
  "bolt_port": 7687,
  "bolt_raft_port":8000,
  "bolt_raft_node_id":3,
  "bolt_raft_init_peers":[
    {"bolt_raft_node_id":1,"ip":"172.20.10.52","bolt_raft_port":8000,"bolt_port":7687},
    {"bolt_raft_node_id":2,"ip":"172.20.10.53","bolt_raft_port":8000,"bolt_port":7687},
    {"bolt_raft_node_id":3,"ip":"172.20.10.54","bolt_raft_port":8000,"bolt_port":7687}
  ],
  "verbose" : 1,
  "log_dir" : "/var/log/lgraph_log",
  "disable_auth" : false,
  "ssl_auth" : false,
  "server_key" : "/usr/local/etc/lgraph/server-key.pem",
  "server_cert" : "/usr/local/etc/lgraph/server-cert.pem",
  "web" : "/usr/local/share/lgraph/browser-resource"
}
```

配置说明

* `port`: web端口。
* `bolt_port`: 对外使用，bolt客户端连接的端口。
* `bolt_raft_port`: 集群内部使用，raft集群内部互相通信时所用的端口，bolt客户端不要连接这个。
* `bolt_raft_node_id`: raft集群节点id，整个集群每个节点要唯一。
* `bolt_raft_init_peers`: raft集群首次初始化的时候使用，里面记录了每个节点的`bolt_raft_node_id`, `ip`, `bolt_raft_port`, `bolt_port` 这样每个节点都知道其他节点的通信信息，可以互相通信。

raft集群的4个核心配置参数是`bolt_port`,`bolt_raft_port`,`bolt_raft_node_id`,`bolt_raft_init_peers`。

请注意，通过RPC协议创建集群时的配置项，例如`enable_ha`、`ha_node_join_group_s`等，不要出现在通过Bolt创建HA集群的配置文件中。

### 启动服务

请按照以下步骤进入 tugraph_ha 容器并执行相关命令以启动服务：

1.进入容器

```
docker exec -it tugrapn_ha bash
```

2.启动服务

```
lgraph_server -c /usr/local/etc/lgraph.json -d start
```

### 查看集群成员信息

可以向集群中任意一个节点发送，返回成员列表以及leader信息。

``
CALL db.bolt.listRaftNodes()
``

### 查看节点的raft状态信息.

可以向集群中任意一个节点发送，返回每个节点自己的raft状态信息。

``
CALL db.bolt.getRaftStatus()
``

## 删除/添加节点

下面模拟某一个节点意外停止服务（kill该节点服务进程），将停止服务的节点删去，重新添加一个节点。

### 删除节点

将节点id是`3`的实例从集群中删除，只能在leader节点执行。

```
CALL db.bolt.removeRaftNode(3)
```

删除后再次查看集群成员信息，可以看到id是`3`的实例已经被清除。

### 添加新节点

添加节点id是`4`的实例，初始化操作可以参考前面创建集群的"前期准备"章节，这时先不要启动lgraph_server服务。

添加一个新节点到集群，节点id是`4`，ip是`172.20.10.41`, `bolt_port`是`7687`, `bolt_raft_port`是`8000`。添加新节点只能在leader节点执行。

```
 CALL db.bolt.addRaftNode(4, '172.20.10.41', 7687, 8000)
```

需要注意的是，通过执行`addRaftNode`添加新节点之后需要手动做一次离线的全量数据同步才能启动新节点的lgraph_server服务。完成这一过程后，当新的节点服务启动并运行时，任何进一步的增量数据写入将会被自动同步。全量数据同步可以直接替换执行docker run命令创建容器时挂载出来的tugraph目录。具体步骤如下：
1. 停止新节点容器。
2. 用任一正常服务节点的tugraph目录，替换新节点执行docker run命令创建容器时挂载出来的tugraph目录。
3. 启动新节点容器。
4. 进入容器修改配置文件，配置文件示例：

```
 {
"directory" : "/var/lib/lgraph/data",
"host" : "172.20.10.41",
"port" : 7070,
"bolt_port": 7687,
"bolt_raft_port":8000,
"bolt_raft_node_id":4,
"bolt_raft_init_peers":[
{"bolt_raft_node_id":1,"ip":"172.20.10.52","bolt_raft_port":8000,"bolt_port":7687},
{"bolt_raft_node_id":2,"ip":"172.20.10.53","bolt_raft_port":8000,"bolt_port":7687},
{"bolt_raft_node_id":4,"ip":"172.20.10.41","bolt_raft_port":8000,"bolt_port":7687}
],
"verbose" : 1,
"log_dir" : "/var/log/lgraph_log",
"disable_auth" : false,
"ssl_auth" : false,
"server_key" : "/usr/local/etc/lgraph/server-key.pem",
"server_cert" : "/usr/local/etc/lgraph/server-cert.pem",
"web" : "/usr/local/share/lgraph/browser-resource"
}
```

5.启动服务

```
lgraph_server -c /usr/local/etc/lgraph.json -d start
```

## 添加learner节点

```
CALL db.bolt.addRaftLearnerNode(5, '172.20.10.42', 7687, 8000)
```

只能在leader节点执行，具体流程可参考上述"添加新节点"的步骤，learner节点不参与选举投票，只同步数据。

## bolt客户端连接实例

### python

```
from neo4j import GraphDatabase

def custom_resolver(address):
    if address == ('mycluster.com', 9999):
        return [
            ('172.20.10.52', 7687),
            ('172.20.10.53', 7687),
            ('172.20.10.54', 7687)
        ]
    else:
        return [address]


if __name__ == '__main__':
    driver = GraphDatabase.driver(
        "neo4j://mycluster.com:9999",
        auth=("admin", "73@TuGraph"),
        resolver=custom_resolver
    )
    session = driver.session(database="default")
    session.run("CALL db.dropDB()")
    session.run("CALL db.createVertexLabel('person', 'id' , 'id', 'INT32', false, 'count', 'INT64', false)")
    session.run("create (n1:person {id:1, count:0})")
    session.close()
    driver.close()
```

`mycluster.com:9999`是一个不存在的假的域名地址, GraphDatabase driver初始化的第三个参数传入一个定制化的resolver解析器`custom_resolver`, `custom_resolver`里面的逻辑是当域名地址是`mycluster.com:9999`的时候，返回三个集群地址。